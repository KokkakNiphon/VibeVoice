# Core dependencies
torch>=2.0.0
torchvision
torchaudio
transformers>=4.51.3,<5.0.0
accelerate>=0.20.0

# Audio processing
llvmlite>=0.40.0
numba>=0.57.0
librosa>=0.10.0
pydub>=0.25.0
av>=10.0.0

# Diffusion and ML
diffusers>=0.21.0
ml-collections>=0.1.1

# Utilities
tqdm>=4.65.0
numpy>=1.24.0,<2.0.0
scipy>=1.10.0
absl-py>=1.4.0
requests>=2.31.0

# Web and API
gradio>=4.0.0
fastapi>=0.100.0
uvicorn[standard]>=0.23.0
aiortc>=1.6.0

# Flash Attention - prebuilt wheels from Dao-AILab
# Install with: pip install flash-attn --no-build-isolation --find-links https://github.com/Dao-AILab/flash-attention/releases
# Or use the setup-script.sh which handles this automatically
flash-attn>=2.6.0; platform_system != "Windows"

# vLLM for ASR inference
vllm>=0.4.0

# Optional: For development
pytest>=7.0.0
black>=23.0.0
isort>=5.12.0
flake8>=6.0.0
